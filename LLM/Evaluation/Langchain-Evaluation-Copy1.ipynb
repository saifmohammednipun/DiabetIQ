{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b4388b4-93d5-4f49-85c4-d9c4964eb50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "langsmith_api_key = os.getenv('LANGSMITH_API_KEY')\n",
    "huggingface_api_key = os.getenv('HUGGINGFACE_API_KEY')\n",
    "\n",
    "os.environ['LANGSMITH_TRACING'] = 'true'\n",
    "os.environ['LANGSMITH_API_KEY'] = langsmith_api_key\n",
    "os.environ['HUGGINGFACE_API_KEY'] = huggingface_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0cd38e6-83c7-45a3-a463-344532873e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader # Use this\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d4d52f-3d9c-43f4-b466-eecd53b0d0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and Processing PDFs...\n",
      "-> Loading: BES-COVID-Pract-Recomnd-06-June-Final-Copy.pdf\n",
      "   Loaded 38 pages.\n",
      "-> Loading: BES-Ramadan-Guideline-2020-min.pdf\n",
      "   Loaded 46 pages.\n",
      "-> Loading: Diabetes_Care_BADAS_guideline2019-3.pdf\n",
      "   Loaded 79 pages.\n",
      "-> Loading: Insulin-Guideline-min.pdf\n",
      "   Loaded 93 pages.\n",
      "\n",
      "Total documents loaded: 256\n",
      "\n",
      "Sample Document Metadata (first doc):\n",
      "{'producer': 'Nitro PDF PrimoPDF', 'creator': 'PrimoPDF http://www.primopdf.com', 'creationdate': '2020-06-07T20:17:39-06:00', 'moddate': '2020-06-07T20:17:39-06:00', 'title': 'Microsoft Word - BES COVID Pract Recomnd 06 June Final Copy', 'author': 'Mir', 'source': 'BES-COVID-Pract-Recomnd-06-June-Final-Copy.pdf', 'total_pages': 38, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "Sample Document Content (first 500 chars of first doc):\n",
      "Bangladesh Endocrine Society (BES) \n",
      "Practical Recommendations for Management of \n",
      "Diabetes and Other Endocrine Diseases in Patients with \n",
      "COVID-19 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Published Online June 2020 \n",
      " \n",
      " \n",
      "All rights reserved by: Bangladesh Endocrine Society (BES) \n",
      " \n",
      " \n",
      "Published by \n",
      "Bangladesh Endocrine Society (BES) \n",
      "Website: http://bes-org.net \n",
      "E-mail: \n",
      "endobd2012@gmail.com\n"
     ]
    }
   ],
   "source": [
    "pdf_files = [\n",
    "    r\"F:\\DiabetIQ\\LLM\\PDFs\\BES-COVID-Pract-Recomnd-06-June-Final-Copy.pdf\",\n",
    "    r\"F:\\DiabetIQ\\LLM\\PDFs\\BES-Ramadan-Guideline-2020-min.pdf\",\n",
    "    r\"F:\\DiabetIQ\\LLM\\PDFs\\Diabetes_Care_BADAS_guideline2019-3.pdf\",\n",
    "    r\"F:\\DiabetIQ\\LLM\\PDFs\\Insulin-Guideline-min.pdf\"\n",
    "]\n",
    "\n",
    "all_docs = [] # Will store LangChain Document objects\n",
    "\n",
    "print(\"Loading and Processing PDFs...\")\n",
    "for pdf_path in pdf_files:\n",
    "    try:\n",
    "        # Extract filename for metadata\n",
    "        file_name = os.path.basename(pdf_path)\n",
    "        print(f\"-> Loading: {file_name}\")\n",
    "\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        # Load pages as individual documents. Each doc will have metadata['page']\n",
    "        pages = loader.load_and_split() # This does basic splitting\n",
    "\n",
    "        # Add source filename to metadata for each page/document\n",
    "        for page_doc in pages:\n",
    "            page_doc.metadata['source'] = file_name\n",
    "            # Optional: clean up page content slightly if needed\n",
    "            # page_doc.page_content = page_doc.page_content.replace('\\n', ' ').strip()\n",
    "\n",
    "        all_docs.extend(pages)\n",
    "        print(f\"   Loaded {len(pages)} pages.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {pdf_path}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal documents loaded: {len(all_docs)}\")\n",
    "if all_docs:\n",
    "    print(\"\\nSample Document Metadata (first doc):\")\n",
    "    print(all_docs[0].metadata)\n",
    "    print(\"\\nSample Document Content (first 500 chars of first doc):\")\n",
    "    print(all_docs[0].page_content[:500])\n",
    "else:\n",
    "    print(\"\\nNo documents were loaded successfully.\")\n",
    "    # Consider exiting or handling this error appropriately\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "411eec36-c71e-47b1-bcf2-6a247991c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \", \", \" \", \"\"],\n",
    "    length_function=len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5bc65c4-d068-46d2-8f90-23470940c849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total chunks created: 702\n",
      "\n",
      "Sample Chunk Metadata (first chunk):\n",
      "{'producer': 'Nitro PDF PrimoPDF', 'creator': 'PrimoPDF http://www.primopdf.com', 'creationdate': '2020-06-07T20:17:39-06:00', 'moddate': '2020-06-07T20:17:39-06:00', 'title': 'Microsoft Word - BES COVID Pract Recomnd 06 June Final Copy', 'author': 'Mir', 'source': 'BES-COVID-Pract-Recomnd-06-June-Final-Copy.pdf', 'total_pages': 38, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "Sample Chunk Content (first 500 chars):\n",
      "Bangladesh Endocrine Society (BES) \n",
      "Practical Recommendations for Management of \n",
      "Diabetes and Other Endocrine Diseases in Patients with \n",
      "COVID-19 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Published Online June 2020 \n",
      " \n",
      " \n",
      "All rights reserved by: Bangladesh Endocrine Society (BES) \n",
      " \n",
      " \n",
      "Published by \n",
      "Bangladesh Endocrine Society (BES) \n",
      "Website: http://bes-org.net \n",
      "E-mail: \n",
      "endobd2012@gmail.com\n"
     ]
    }
   ],
   "source": [
    "chunks = text_splitter.split_documents(all_docs)\n",
    "\n",
    "print(f\"\\nTotal chunks created: {len(chunks)}\")\n",
    "if chunks:\n",
    "    print(\"\\nSample Chunk Metadata (first chunk):\")\n",
    "    print(chunks[0].metadata)\n",
    "    print(\"\\nSample Chunk Content (first 500 chars):\")\n",
    "    print(chunks[0].page_content[:500])\n",
    "else:\n",
    "    print(\"\\nNo chunks were created. Check splitting process.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "469c5497-9fc3-4614-a72e-b5729c4f6156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nInitializing Embedding Model...\n",
      "\\nCreating Vector Store (ChromaDB)...\n",
      "\n",
      "Creating/Overwriting vector store in: chroma_db_diabetiq\n",
      "Vector Store Created and Persisted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\4175222579.py:15: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist() # Explicitly persist the data to disk\n"
     ]
    }
   ],
   "source": [
    "print(\"\\\\nInitializing Embedding Model...\")\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"intfloat/e5-small-v2\")\n",
    "\n",
    "print(\"\\\\nCreating Vector Store (ChromaDB)...\\n\")\n",
    "\n",
    "# Define a directory to persist the database\n",
    "persist_directory = \"chroma_db_diabetiq\"\n",
    "\n",
    "print(f\"Creating/Overwriting vector store in: {persist_directory}\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=persist_directory # Use the persistent directory\n",
    ")\n",
    "vectorstore.persist() # Explicitly persist the data to disk\n",
    "print(\"Vector Store Created and Persisted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8099d3b3-1b42-4b0c-8881-ba377501da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5}) # Retrieve top 5 chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ece2fd5-8f00-45b0-b4ef-afe7f1d107bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "\n",
    "# Initialize Ollama with Mistral model\n",
    "llm = OllamaLLM(\n",
    "    model=\"mistral\",\n",
    "    temperature=0.7,  # Slightly lower temperature for more focused medical responses\n",
    "    system=\"You are a medical assistant specialized in diabetes care.\"\n",
    ")\n",
    "\n",
    "@traceable()\n",
    "def rag_bot(question: str) -> dict:\n",
    "    # LangChain retriever will be automatically traced\n",
    "    docs = retriever.invoke(question)\n",
    "    docs_string = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    instructions = f\"\"\"You are DiabetIQ, an AI assistant specialized in diabetes management.\n",
    "    Use the following clinical sources to answer the patient's question accurately and safely.\n",
    "    Follow these rules strictly:\n",
    "    1. Provide only evidence-based medical information\n",
    "    2. Never give dosage advice without \"consult your doctor\" disclaimer\n",
    "    3. Flag any conflicting information in sources\n",
    "    4. Keep answers concise (2-3 sentences maximum)\n",
    "    5. If unsure, say \"I recommend consulting your healthcare provider\"\n",
    "\n",
    "    Clinical Sources:\n",
    "    {docs_string}\n",
    "\n",
    "    Patient Question: {question}\"\"\"\n",
    "\n",
    "    # Invoke Mistral via Ollama\n",
    "    response = llm.invoke(instructions)\n",
    "    \n",
    "    return {\n",
    "        \"answer\": response,\n",
    "        \"documents\": docs,\n",
    "        \"sources\": [doc.metadata.get('source', '') for doc in docs]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0d7b12a-2f94-4ab6-bf33-dbd6c4041108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['007b2d71-0f49-4653-9d5c-a503fb33a636',\n",
       "  '78ab8ac1-c948-4432-aa6b-0c4b50ab8c3f',\n",
       "  '762cb77a-b8c2-4e9e-a227-54f3819d45ad',\n",
       "  'fde78be0-c2eb-4f63-8bc5-76423157ef83',\n",
       "  '368090e5-0d59-4d87-9108-05b004a22707'],\n",
       " 'count': 5}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What are common symptoms of low blood sugar (hypoglycemia)?\"},\n",
    "        \"outputs\": {\"answer\": \"Common symptoms of hypoglycemia include shakiness, sweating, dizziness, confusion, rapid heartbeat, hunger, and irritability. Severe cases can lead to loss of consciousness. It's important to treat it promptly.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"How can I use the DiabetIQ app to log my meals?\"},\n",
    "        \"outputs\": {\"answer\": \"In the DiabetIQ app, navigate to the 'Log' or 'Diary' section, select 'Meal', and enter details like the food items, portion sizes, estimated carbohydrates, and the time of the meal. Saving this helps track your dietary intake.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Why is monitoring blood glucose levels important for diabetes management?\"},\n",
    "        \"outputs\": {\"answer\": \"Monitoring blood glucose helps you understand how food, activity, medication, and stress affect your levels. This information empowers you and your healthcare team to make informed decisions about your treatment plan to maintain target ranges and prevent complications.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Can DiabetIQ help predict my risk of high blood sugar?\"},\n",
    "        \"outputs\": {\"answer\": \"DiabetIQ uses machine learning based on your logged data (like meals, activity, glucose readings) to identify patterns and potentially indicate an increased short-term risk of high blood sugar (hyperglycemia). This feature is for informational purposes to help you be proactive and should be discussed with your healthcare provider.\"},\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What type of exercise is good for managing diabetes?\"},\n",
    "        \"outputs\": {\"answer\": \"A combination of aerobic exercise (like brisk walking, swimming, cycling) and resistance training (like lifting weights or using resistance bands) is generally recommended. Always consult your doctor before starting any new exercise program to ensure it's safe and appropriate for you.\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Create the dataset and examples in LangSmith\n",
    "dataset_name = \"Dataset4\"\n",
    "dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "client.create_examples(\n",
    "    dataset_id=dataset.id,\n",
    "    examples=examples\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fd8a71-6d1a-4e14-a1d2-efe5cd9b543b",
   "metadata": {},
   "source": [
    "# Correctness: Response vs reference answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bd20540-9b4a-41e7-8d7c-1c534305112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "import json # Import json for potential parsing, though simple string check might suffice\n",
    "\n",
    "# output schema (Kept for documentation, but not enforced by LLM directly)\n",
    "class CorrectnessGrade(TypedDict):\n",
    "    explanation: Annotated[str, ..., \"Detailed clinical reasoning for diabetes management accuracy\"]\n",
    "    correct: Annotated[bool, ..., \"True if answer is medically accurate for diabetes care\"]\n",
    "\n",
    "\n",
    "# prompt\n",
    "correctness_instructions = \"\"\"You are an expert evaluator assessing the factual accuracy of chatbot responses in DiabetIQ: an intelligent diabetes management application with an integrated LLM-augmented chatbot.\n",
    "\n",
    "You will be given:\n",
    "- A USER QUESTION (related to diabetes care, management, medications, symptoms, etc.)\n",
    "- A GROUND TRUTH ANSWER (clinically accurate and verified information)\n",
    "- A CHATBOT RESPONSE (generated by the DiabetIQ chatbot)\n",
    "\n",
    "Your task is to evaluate the **correctness** of the chatbot’s response according to the following criteria:\n",
    "\n",
    "(1) Evaluate only the factual accuracy of the chatbot response **relative to the ground truth**. Do not grade based on style, formatting, or tone.\n",
    "(2) Ensure the chatbot response **does not include any incorrect or misleading information** compared to the ground truth.\n",
    "(3) It is acceptable if the chatbot includes **additional medically accurate** information, as long as it does not contradict or misrepresent the ground truth.\n",
    "(4) Pay special attention to **clinical accuracy**, especially for medications, insulin usage, dietary advice, blood glucose targets, or symptom interpretation.\n",
    "\n",
    "Correctness:\n",
    "- A correctness value of **True** means the chatbot's answer is entirely consistent with and accurate relative to the ground truth.\n",
    "- A correctness value of **False** means the chatbot's answer contains inaccuracies, contradictions, or medically misleading content.\n",
    "\n",
    "Provide a **step-by-step explanation** for your judgment. Do not begin by stating the correct answer. Instead, walk through your analysis comparing the chatbot response to the ground truth carefully and clearly.\n",
    "**Finally, conclude your response with 'Final Grade: True' or 'Final Grade: False'.**\n",
    "\n",
    "Be rigorous and thoughtful in your evaluation — patient safety depends on accurate information.\n",
    "\"\"\"\n",
    "\n",
    "# LLM - REMOVED .with_structured_output\n",
    "grader_llm = OllamaLLM(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0,\n",
    "    # system=correctness_instructions # System prompt often passed differently or with invoke\n",
    ")\n",
    "\n",
    "def correctness(inputs: dict, outputs: dict, reference_outputs: dict) -> dict:\n",
    "    \"\"\"An evaluator for RAG answer accuracy. Returns score and reasoning.\"\"\"\n",
    "    evaluator_input_prompt = f\"\"\"{correctness_instructions}\n",
    "\n",
    "QUESTION: {inputs['question']}\n",
    "GROUND TRUTH ANSWER: {reference_outputs['answer']}\n",
    "CHATBOT RESPONSE: {outputs['answer']}\"\"\"\n",
    "\n",
    "    # Run evaluator\n",
    "    grade_str = grader_llm.invoke(evaluator_input_prompt)\n",
    "\n",
    "    # Parse the output string\n",
    "    score = None\n",
    "    reasoning = grade_str # Default reasoning is the full output\n",
    "    if \"final grade: true\" in grade_str.lower():\n",
    "        score = 1.0 # LangSmith expects 1 for True/Correct, 0 for False/Incorrect\n",
    "        # Optional: Extract reasoning before the final grade line if needed\n",
    "        reasoning = grade_str.lower().split(\"final grade: true\")[0].strip()\n",
    "    elif \"final grade: false\" in grade_str.lower():\n",
    "        score = 0.0\n",
    "        reasoning = grade_str.lower().split(\"final grade: false\")[0].strip()\n",
    "    else:\n",
    "        # Handle cases where the LLM didn't follow instructions\n",
    "        print(f\"Warning: Could not parse correctness grade from output: {grade_str}\")\n",
    "        # You might decide to default to False (0.0) or handle as an error\n",
    "        score = 0.0 # Defaulting to incorrect if parsing fails\n",
    "\n",
    "    return {\"score\": score, \"reasoning\": reasoning}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee695bb4-3a5f-4176-8a7f-038978127378",
   "metadata": {},
   "source": [
    "# Relevance: Response vs input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f28b178a-47d6-43d2-b596-8bca6d1dbf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output schema (Documentation only)\n",
    "class RelevanceGrade(TypedDict):\n",
    "    explanation: Annotated[str, ..., \"Clinical relevance analysis for diabetes context\"]\n",
    "    relevant: Annotated[bool, ..., \"Whether answer properly addresses medical question\"]\n",
    "\n",
    "# Grade prompt\n",
    "relevance_instructions = \"\"\"You are an expert evaluator assessing the relevance of chatbot responses in DiabetIQ: an intelligent diabetes management application with an integrated LLM-augmented chatbot.\n",
    "\n",
    "You will be given:\n",
    "- A USER QUESTION (related to diabetes care, management, medications, lifestyle, etc.)\n",
    "- A CHATBOT RESPONSE (generated by the DiabetIQ chatbot)\n",
    "\n",
    "Your task is to evaluate the **relevance** of the chatbot’s response according to the following criteria:\n",
    "\n",
    "(1) Ensure the CHATBOT RESPONSE is **concise** and **directly relevant** to the USER QUESTION. It should stay on topic and not introduce unrelated or tangential information.\n",
    "(2) Ensure the CHATBOT RESPONSE **meaningfully helps to answer the USER QUESTION**, either by providing actionable guidance, informative clarification, or medically appropriate context.\n",
    "\n",
    "Relevance:\n",
    "- A relevance value of **True** means the chatbot's response meets both criteria and contributes directly to answering the user’s question.\n",
    "- A relevance value of **False** means the chatbot's response is off-topic, overly verbose without added value, or does not clearly address the user's question.\n",
    "\n",
    "Provide a **step-by-step explanation** for your decision. Do not begin by stating the final judgment. Instead, walk through how the response aligns (or does not align) with the user's question to ensure your reasoning is sound and clear.\n",
    "**Finally, conclude your response with 'Final Grade: True' or 'Final Grade: False'.**\n",
    "\n",
    "This evaluation helps ensure the chatbot provides focused and helpful responses to people managing their diabetes.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# LLM\n",
    "relevance_llm = OllamaLLM(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0,\n",
    "    # system=relevance_instructions\n",
    ")\n",
    "\n",
    "# Evaluator\n",
    "def relevance(inputs: dict, outputs: dict) -> dict:\n",
    "    \"\"\"A simple evaluator for RAG answer relevance. Returns score and reasoning.\"\"\"\n",
    "    evaluator_input_prompt = f\"\"\"{relevance_instructions}\n",
    "\n",
    "USER QUESTION: {inputs['question']}\n",
    "CHATBOT RESPONSE: {outputs['answer']}\"\"\"\n",
    "\n",
    "    grade_str = relevance_llm.invoke(evaluator_input_prompt)\n",
    "\n",
    "    # Parse the output string\n",
    "    score = None\n",
    "    reasoning = grade_str\n",
    "    if \"final grade: true\" in grade_str.lower():\n",
    "        score = 1.0\n",
    "        reasoning = grade_str.lower().split(\"final grade: true\")[0].strip()\n",
    "    elif \"final grade: false\" in grade_str.lower():\n",
    "        score = 0.0\n",
    "        reasoning = grade_str.lower().split(\"final grade: false\")[0].strip()\n",
    "    else:\n",
    "        print(f\"Warning: Could not parse relevance grade from output: {grade_str}\")\n",
    "        score = 0.0 # Defaulting to irrelevant\n",
    "\n",
    "    return {\"score\": score, \"reasoning\": reasoning}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d261b0-cc17-4496-bbcc-014c4064b1c8",
   "metadata": {},
   "source": [
    "# Groundedness: Response vs retrieved docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6425e852-03c1-4afa-a4ea-315e50551260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell [33] - MODIFIED\n",
    "\n",
    "# Grade output schema (Documentation only)\n",
    "class GroundedGrade(TypedDict):\n",
    "    explanation: Annotated[str, ..., \"Explain your reasoning for the score\"]\n",
    "    grounded: Annotated[bool, ..., \"Provide the score on if the answer hallucinates from the documents\"]\n",
    "\n",
    "# Grade prompt\n",
    "grounded_instructions = \"\"\"You are an expert evaluator assessing the groundedness of chatbot responses in DiabetIQ: an intelligent diabetes management application with an integrated LLM-augmented chatbot.\n",
    "\n",
    "You will be given:\n",
    "- A set of FACTS (retrieved evidence, clinical references, or authoritative information)\n",
    "- A CHATBOT RESPONSE (generated by the DiabetIQ chatbot)\n",
    "\n",
    "Your task is to evaluate the **groundedness** of the chatbot’s response according to the following criteria:\n",
    "\n",
    "(1) Ensure the CHATBOT RESPONSE is **based on and supported by the provided FACTS**.\n",
    "(2) Ensure the CHATBOT RESPONSE does **not include hallucinated or fabricated information** that is not supported by or inferable from the FACTS.\n",
    "\n",
    "Grounded:\n",
    "- A grounded value of **True** means the chatbot's response remains strictly within the bounds of the provided FACTS and is properly supported by them.\n",
    "- A grounded value of **False** means the chatbot's response includes unsupported claims, makes assumptions not backed by the facts, or introduces external/hallucinated information.\n",
    "\n",
    "Explain your reasoning in a **step-by-step** manner to ensure your conclusion is accurate and well-justified. Focus on whether each part of the chatbot response can be traced back to the given facts.\n",
    "**Finally, conclude your response with 'Final Grade: True' or 'Final Grade: False'.**\n",
    "\n",
    "This evaluation is crucial to ensure the chatbot provides users with reliable, evidence-based diabetes management information.\n",
    "\"\"\"\n",
    "\n",
    "# LLM\n",
    "grounded_llm =  OllamaLLM(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0,\n",
    "    # system=grounded_instructions # Pass prompt during invoke\n",
    ")\n",
    "\n",
    "# Evaluator\n",
    "def groundedness(inputs: dict, outputs: dict) -> dict:\n",
    "    \"\"\"A simple evaluator for RAG answer groundedness. Returns score and reasoning.\"\"\"\n",
    "    # Check if documents exist in outputs, handle gracefully if not (e.g., due to upstream error)\n",
    "    if \"documents\" not in outputs or not outputs[\"documents\"]:\n",
    "         print(\"Warning: No documents found in outputs for groundedness check.\")\n",
    "         return {\"score\": 0.0, \"reasoning\": \"No documents retrieved to check groundedness against.\"}\n",
    "    if \"answer\" not in outputs:\n",
    "        print(\"Warning: No answer found in outputs for groundedness check.\")\n",
    "        return {\"score\": 0.0, \"reasoning\": \"No answer generated to check groundedness.\"}\n",
    "\n",
    "    doc_string = \"\\\\n\\\\n\".join(doc.page_content for doc in outputs[\"documents\"])\n",
    "    evaluator_input_prompt = f\"\"\"{grounded_instructions}\n",
    "\n",
    "FACTS:\n",
    "{doc_string}\n",
    "\n",
    "CHATBOT RESPONSE:\n",
    "{outputs['answer']}\"\"\"\n",
    "\n",
    "    grade_str = grounded_llm.invoke(evaluator_input_prompt)\n",
    "\n",
    "    # Parse the output string\n",
    "    score = None\n",
    "    reasoning = grade_str\n",
    "    if \"final grade: true\" in grade_str.lower():\n",
    "        score = 1.0\n",
    "        reasoning = grade_str.lower().split(\"final grade: true\")[0].strip()\n",
    "    elif \"final grade: false\" in grade_str.lower():\n",
    "        score = 0.0\n",
    "        reasoning = grade_str.lower().split(\"final grade: false\")[0].strip()\n",
    "    else:\n",
    "        print(f\"Warning: Could not parse groundedness grade from output: {grade_str}\")\n",
    "        score = 0.0 # Defaulting to not grounded\n",
    "\n",
    "    return {\"score\": score, \"reasoning\": reasoning}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba331b1-4449-459a-8811-bbcf844ac6de",
   "metadata": {},
   "source": [
    "# Retrieval relevance: Retrieved docs vs input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58180527-0758-445f-953d-f82aa922a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade output schema (Documentation only)\n",
    "class RetrievalRelevanceGrade(TypedDict):\n",
    "    explanation: Annotated[str, ..., \"Explain your reasoning for the score\"]\n",
    "    relevant: Annotated[bool, ..., \"True if the retrieved documents are relevant to the question, False otherwise\"]\n",
    "\n",
    "# Grade prompt\n",
    "retrieval_relevance_instructions = \"\"\"You are an expert evaluator assessing the relevance of retrieved information used by DiabetIQ: an intelligent diabetes management application with an integrated LLM-augmented chatbot.\n",
    "\n",
    "You will be given:\n",
    "- A USER QUESTION (related to diabetes care, treatment, lifestyle, or symptoms)\n",
    "- A set of FACTS (documents or text segments retrieved by the system to support answering the question)\n",
    "\n",
    "Your task is to evaluate the **retrieval relevance** of the FACTS using the following criteria:\n",
    "\n",
    "(1) Your goal is to identify FACTS that are **completely unrelated** to the USER QUESTION.\n",
    "(2) If the FACTS contain **any keywords or semantic meaning related to the QUESTION**, consider them relevant.\n",
    "(3) It is acceptable if the FACTS include some unrelated information, as long as the overall content is topically or semantically related to the question.\n",
    "\n",
    "Relevance:\n",
    "- A relevance value of **True** means the FACTS contain **any** keywords, concepts, or medically relevant semantic meaning tied to the USER QUESTION and are therefore relevant.\n",
    "- A relevance value of **False** means the FACTS are **entirely unrelated** to the USER QUESTION and offer no value in helping answer it.\n",
    "\n",
    "Provide a **step-by-step explanation** of your reasoning. Begin by analyzing the QUESTION and the FACTS, then determine if any part of the retrieved content helps address the question, even partially or indirectly.\n",
    "**Finally, conclude your response with 'Final Grade: True' or 'Final Grade: False'.**\n",
    "\n",
    "This evaluation ensures that DiabetIQ retrieves clinically meaningful information that aligns with user needs.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Grader LLM\n",
    "retrieval_relevance_llm = OllamaLLM(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0,\n",
    "    # system=retrieval_relevance_instructions # Pass prompt during invoke\n",
    ")\n",
    "\n",
    "def retrieval_relevance(inputs: dict, outputs: dict) -> dict:\n",
    "    \"\"\"An evaluator for document relevance. Returns score and reasoning.\"\"\"\n",
    "    # Check if documents exist\n",
    "    if \"documents\" not in outputs or not outputs[\"documents\"]:\n",
    "         print(\"Warning: No documents found in outputs for retrieval relevance check.\")\n",
    "         # If no docs retrieved, are they relevant? Arguably No.\n",
    "         return {\"score\": 0.0, \"reasoning\": \"No documents retrieved to check relevance.\"}\n",
    "\n",
    "    doc_string = \"\\\\n\\\\n\".join(doc.page_content for doc in outputs[\"documents\"])\n",
    "    evaluator_input_prompt = f\"\"\"{retrieval_relevance_instructions}\n",
    "\n",
    "USER QUESTION: {inputs['question']}\n",
    "\n",
    "FACTS:\n",
    "{doc_string}\"\"\"\n",
    "\n",
    "    # Run evaluator\n",
    "    grade_str = retrieval_relevance_llm.invoke(evaluator_input_prompt)\n",
    "\n",
    "    # Parse the output string\n",
    "    score = None\n",
    "    reasoning = grade_str\n",
    "    if \"final grade: true\" in grade_str.lower():\n",
    "        score = 1.0\n",
    "        reasoning = grade_str.lower().split(\"final grade: true\")[0].strip()\n",
    "    elif \"final grade: false\" in grade_str.lower():\n",
    "        score = 0.0\n",
    "        reasoning = grade_str.lower().split(\"final grade: false\")[0].strip()\n",
    "    else:\n",
    "        print(f\"Warning: Could not parse retrieval relevance grade from output: {grade_str}\")\n",
    "        score = 0.0 # Defaulting to irrelevant\n",
    "\n",
    "    return {\"score\": score, \"reasoning\": reasoning}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16b44a6-a31f-40be-b259-b98159179ad9",
   "metadata": {},
   "source": [
    "# Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c1e93a4-0f1c-463f-9f2a-d0593709d4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'rag-doc-relevance-80545ed0' at:\n",
      "https://smith.langchain.com/o/8b01a444-dc7f-43ed-9ee5-160cfa7a7fc7/datasets/f2a71478-1fae-4e3e-b055-e15dbe3ae6d4/compare?selectedSessions=ce892518-2842-4436-a86a-5cba0bd65066\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff54da1b2d94282a1346691d8b425e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 101, in handle_request\n",
      "    raise exc\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 78, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 124, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_backends\\sync.py\", line 207, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 635, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\3127263961.py\", line 2, in target\n",
      "    return rag_bot(inputs[\"question\"])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 635, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\3902628271.py\", line 31, in rag_bot\n",
      "    response = llm.invoke(instructions)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 387, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 764, in generate_prompt\n",
      "    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 971, in generate\n",
      "    return self._generate_helper(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 790, in _generate_helper\n",
      "    self._generate(\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_ollama\\llms.py\", line 290, in _generate\n",
      "    final_chunk = self._stream_with_aggregation(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_ollama\\llms.py\", line 258, in _stream_with_aggregation\n",
      "    for stream_resp in self._create_generate_stream(prompt, stop, **kwargs):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_ollama\\llms.py\", line 213, in _create_generate_stream\n",
      "    yield from self._client.generate(\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\ollama\\_client.py\", line 163, in inner\n",
      "    with self._client.stream(*args, **kwargs) as r:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 137, in __enter__\n",
      "    return next(self.gen)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 868, in stream\n",
      "    response = self.send(\n",
      "               ^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 1014, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 97372f0d-5b56-4643-a4a3-cc00453da46c: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 635, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\3739266646.py\", line 48, in correctness\n",
      "    CHATBOT RESPONSE: {outputs['answer']}\"\"\"\n",
      "                       ~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator relevance> on run 97372f0d-5b56-4643-a4a3-cc00453da46c: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 635, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\3155717442.py\", line 42, in relevance\n",
      "    CHATBOT RESPONSE: {outputs['answer']}\"\"\"\n",
      "                       ~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No documents found in outputs for groundedness check.\n",
      "Warning: No documents found in outputs for retrieval relevance check.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 101, in handle_request\n",
      "    raise exc\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 78, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 124, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_backends\\sync.py\", line 207, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 635, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\3127263961.py\", line 2, in target\n",
      "    return rag_bot(inputs[\"question\"])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 635, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\3902628271.py\", line 31, in rag_bot\n",
      "    response = llm.invoke(instructions)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 387, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 764, in generate_prompt\n",
      "    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 971, in generate\n",
      "    return self._generate_helper(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 790, in _generate_helper\n",
      "    self._generate(\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_ollama\\llms.py\", line 290, in _generate\n",
      "    final_chunk = self._stream_with_aggregation(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_ollama\\llms.py\", line 258, in _stream_with_aggregation\n",
      "    for stream_resp in self._create_generate_stream(prompt, stop, **kwargs):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_ollama\\llms.py\", line 213, in _create_generate_stream\n",
      "    yield from self._client.generate(\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\ollama\\_client.py\", line 163, in inner\n",
      "    with self._client.stream(*args, **kwargs) as r:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 137, in __enter__\n",
      "    return next(self.gen)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 868, in stream\n",
      "    response = self.send(\n",
      "               ^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 1014, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 596a95b1-dc29-4752-866c-ebcbdd4f6d0f: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 635, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\3739266646.py\", line 48, in correctness\n",
      "    CHATBOT RESPONSE: {outputs['answer']}\"\"\"\n",
      "                       ~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator relevance> on run 596a95b1-dc29-4752-866c-ebcbdd4f6d0f: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 635, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\3155717442.py\", line 42, in relevance\n",
      "    CHATBOT RESPONSE: {outputs['answer']}\"\"\"\n",
      "                       ~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No documents found in outputs for groundedness check.\n",
      "Warning: No documents found in outputs for retrieval relevance check.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 101, in handle_request\n",
      "    raise exc\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 78, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 124, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_backends\\sync.py\", line 207, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 635, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\3127263961.py\", line 2, in target\n",
      "    return rag_bot(inputs[\"question\"])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 635, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\3902628271.py\", line 31, in rag_bot\n",
      "    response = llm.invoke(instructions)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 387, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 764, in generate_prompt\n",
      "    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 971, in generate\n",
      "    return self._generate_helper(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 790, in _generate_helper\n",
      "    self._generate(\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_ollama\\llms.py\", line 290, in _generate\n",
      "    final_chunk = self._stream_with_aggregation(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_ollama\\llms.py\", line 258, in _stream_with_aggregation\n",
      "    for stream_resp in self._create_generate_stream(prompt, stop, **kwargs):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_ollama\\llms.py\", line 213, in _create_generate_stream\n",
      "    yield from self._client.generate(\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\ollama\\_client.py\", line 163, in inner\n",
      "    with self._client.stream(*args, **kwargs) as r:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 137, in __enter__\n",
      "    return next(self.gen)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 868, in stream\n",
      "    response = self.send(\n",
      "               ^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 1014, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 54ceca8c-640d-45d3-a6ff-eed870d9c275: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 635, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\3739266646.py\", line 48, in correctness\n",
      "    CHATBOT RESPONSE: {outputs['answer']}\"\"\"\n",
      "                       ~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator relevance> on run 54ceca8c-640d-45d3-a6ff-eed870d9c275: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 635, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\3155717442.py\", line 42, in relevance\n",
      "    CHATBOT RESPONSE: {outputs['answer']}\"\"\"\n",
      "                       ~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No documents found in outputs for groundedness check.\n",
      "Warning: No documents found in outputs for retrieval relevance check.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 101, in handle_request\n",
      "    raise exc\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 78, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 124, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_backends\\sync.py\", line 207, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 635, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\3127263961.py\", line 2, in target\n",
      "    return rag_bot(inputs[\"question\"])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 635, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\3902628271.py\", line 31, in rag_bot\n",
      "    response = llm.invoke(instructions)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 387, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 764, in generate_prompt\n",
      "    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 971, in generate\n",
      "    return self._generate_helper(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 790, in _generate_helper\n",
      "    self._generate(\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_ollama\\llms.py\", line 290, in _generate\n",
      "    final_chunk = self._stream_with_aggregation(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_ollama\\llms.py\", line 258, in _stream_with_aggregation\n",
      "    for stream_resp in self._create_generate_stream(prompt, stop, **kwargs):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_ollama\\llms.py\", line 213, in _create_generate_stream\n",
      "    yield from self._client.generate(\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\ollama\\_client.py\", line 163, in inner\n",
      "    with self._client.stream(*args, **kwargs) as r:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 137, in __enter__\n",
      "    return next(self.gen)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 868, in stream\n",
      "    response = self.send(\n",
      "               ^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 1014, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run 47f2a53d-f4e8-4dc3-aa7f-68151a08d1c8: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 635, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\3739266646.py\", line 48, in correctness\n",
      "    CHATBOT RESPONSE: {outputs['answer']}\"\"\"\n",
      "                       ~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator relevance> on run 47f2a53d-f4e8-4dc3-aa7f-68151a08d1c8: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 635, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\3155717442.py\", line 42, in relevance\n",
      "    CHATBOT RESPONSE: {outputs['answer']}\"\"\"\n",
      "                       ~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No documents found in outputs for groundedness check.\n",
      "Warning: No documents found in outputs for retrieval relevance check.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 101, in handle_request\n",
      "    raise exc\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 78, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 124, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_backends\\sync.py\", line 207, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1915, in _forward\n",
      "    fn(\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 635, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\3127263961.py\", line 2, in target\n",
      "    return rag_bot(inputs[\"question\"])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 635, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\3902628271.py\", line 31, in rag_bot\n",
      "    response = llm.invoke(instructions)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 387, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 764, in generate_prompt\n",
      "    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 971, in generate\n",
      "    return self._generate_helper(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 790, in _generate_helper\n",
      "    self._generate(\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_ollama\\llms.py\", line 290, in _generate\n",
      "    final_chunk = self._stream_with_aggregation(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_ollama\\llms.py\", line 258, in _stream_with_aggregation\n",
      "    for stream_resp in self._create_generate_stream(prompt, stop, **kwargs):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langchain_ollama\\llms.py\", line 213, in _create_generate_stream\n",
      "    yield from self._client.generate(\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\ollama\\_client.py\", line 163, in inner\n",
      "    with self._client.stream(*args, **kwargs) as r:\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 137, in __enter__\n",
      "    return next(self.gen)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 868, in stream\n",
      "    response = self.send(\n",
      "               ^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 914, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 942, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 979, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_client.py\", line 1014, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "Error running evaluator <DynamicRunEvaluator correctness> on run fdfd66e7-141b-438f-bd2d-91b00412969d: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 635, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\3739266646.py\", line 48, in correctness\n",
      "    CHATBOT RESPONSE: {outputs['answer']}\"\"\"\n",
      "                       ~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator relevance> on run fdfd66e7-141b-438f-bd2d-91b00412969d: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1634, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 346, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 635, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"F:\\DiabetIQ\\my_env\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 744, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_2704\\3155717442.py\", line 42, in relevance\n",
      "    CHATBOT RESPONSE: {outputs['answer']}\"\"\"\n",
      "                       ~~~~~~~^^^^^^^^^^\n",
      "KeyError: 'answer'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No documents found in outputs for groundedness check.\n",
      "Warning: No documents found in outputs for retrieval relevance check.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.wrapper</th>\n",
       "      <th>feedback.groundedness</th>\n",
       "      <th>feedback.retrieval_relevance</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are common symptoms of low blood sugar (h...</td>\n",
       "      <td>None</td>\n",
       "      <td>ConnectError('[WinError 10061] No connection c...</td>\n",
       "      <td>Common symptoms of hypoglycemia include shakin...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.125989</td>\n",
       "      <td>007b2d71-0f49-4653-9d5c-a503fb33a636</td>\n",
       "      <td>97372f0d-5b56-4643-a4a3-cc00453da46c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What type of exercise is good for managing dia...</td>\n",
       "      <td>None</td>\n",
       "      <td>ConnectError('[WinError 10061] No connection c...</td>\n",
       "      <td>A combination of aerobic exercise (like brisk ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.066696</td>\n",
       "      <td>368090e5-0d59-4d87-9108-05b004a22707</td>\n",
       "      <td>596a95b1-dc29-4752-866c-ebcbdd4f6d0f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why is monitoring blood glucose levels importa...</td>\n",
       "      <td>None</td>\n",
       "      <td>ConnectError('[WinError 10061] No connection c...</td>\n",
       "      <td>Monitoring blood glucose helps you understand ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.055787</td>\n",
       "      <td>762cb77a-b8c2-4e9e-a227-54f3819d45ad</td>\n",
       "      <td>54ceca8c-640d-45d3-a6ff-eed870d9c275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can I use the DiabetIQ app to log my meals?</td>\n",
       "      <td>None</td>\n",
       "      <td>ConnectError('[WinError 10061] No connection c...</td>\n",
       "      <td>In the DiabetIQ app, navigate to the 'Log' or ...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.052808</td>\n",
       "      <td>78ab8ac1-c948-4432-aa6b-0c4b50ab8c3f</td>\n",
       "      <td>47f2a53d-f4e8-4dc3-aa7f-68151a08d1c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can DiabetIQ help predict my risk of high bloo...</td>\n",
       "      <td>None</td>\n",
       "      <td>ConnectError('[WinError 10061] No connection c...</td>\n",
       "      <td>DiabetIQ uses machine learning based on your l...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.061881</td>\n",
       "      <td>fde78be0-c2eb-4f63-8bc5-76423157ef83</td>\n",
       "      <td>fdfd66e7-141b-438f-bd2d-91b00412969d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     inputs.question outputs.output  \\\n",
       "0  What are common symptoms of low blood sugar (h...           None   \n",
       "1  What type of exercise is good for managing dia...           None   \n",
       "2  Why is monitoring blood glucose levels importa...           None   \n",
       "3    How can I use the DiabetIQ app to log my meals?           None   \n",
       "4  Can DiabetIQ help predict my risk of high bloo...           None   \n",
       "\n",
       "                                               error  \\\n",
       "0  ConnectError('[WinError 10061] No connection c...   \n",
       "1  ConnectError('[WinError 10061] No connection c...   \n",
       "2  ConnectError('[WinError 10061] No connection c...   \n",
       "3  ConnectError('[WinError 10061] No connection c...   \n",
       "4  ConnectError('[WinError 10061] No connection c...   \n",
       "\n",
       "                                    reference.answer feedback.wrapper  \\\n",
       "0  Common symptoms of hypoglycemia include shakin...             None   \n",
       "1  A combination of aerobic exercise (like brisk ...             None   \n",
       "2  Monitoring blood glucose helps you understand ...             None   \n",
       "3  In the DiabetIQ app, navigate to the 'Log' or ...             None   \n",
       "4  DiabetIQ uses machine learning based on your l...             None   \n",
       "\n",
       "   feedback.groundedness  feedback.retrieval_relevance  execution_time  \\\n",
       "0                    0.0                           0.0        2.125989   \n",
       "1                    0.0                           0.0        2.066696   \n",
       "2                    0.0                           0.0        2.055787   \n",
       "3                    0.0                           0.0        2.052808   \n",
       "4                    0.0                           0.0        2.061881   \n",
       "\n",
       "                             example_id                                    id  \n",
       "0  007b2d71-0f49-4653-9d5c-a503fb33a636  97372f0d-5b56-4643-a4a3-cc00453da46c  \n",
       "1  368090e5-0d59-4d87-9108-05b004a22707  596a95b1-dc29-4752-866c-ebcbdd4f6d0f  \n",
       "2  762cb77a-b8c2-4e9e-a227-54f3819d45ad  54ceca8c-640d-45d3-a6ff-eed870d9c275  \n",
       "3  78ab8ac1-c948-4432-aa6b-0c4b50ab8c3f  47f2a53d-f4e8-4dc3-aa7f-68151a08d1c8  \n",
       "4  fde78be0-c2eb-4f63-8bc5-76423157ef83  fdfd66e7-141b-438f-bd2d-91b00412969d  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def target(inputs: dict) -> dict:\n",
    "    return rag_bot(inputs[\"question\"])\n",
    "\n",
    "experiment_results = client.evaluate(\n",
    "    target,\n",
    "    data=dataset_name,\n",
    "    evaluators=[correctness, groundedness, relevance, retrieval_relevance],\n",
    "    experiment_prefix=\"rag-doc-relevance\",\n",
    "    metadata={\"version\": \"LCEL context, gpt-4-0125-preview\"},\n",
    ")\n",
    "\n",
    "experiment_results.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7e5449-5113-4a4d-a8f3-8fd5a0ea8b55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
