{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a30e7240-4d5a-4c47-b560-151154a06afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "langchain_api_key = os.getenv('LANGCHAIN_API_KEY')\n",
    "huggingface_api_key = os.getenv('HUGGINGFACE_API_KEY')\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_API_KEY'] = langchain_api_key\n",
    "os.environ['HUGGINGFACE_API_KEY'] = huggingface_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "649d7d14-24aa-4dba-ad0b-5a4f268dcbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64422ab0-fb21-425d-91a2-a26414342264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ragas\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness,\n",
    "    answer_similarity # Often used with answer_correctness\n",
    ")\n",
    "from ragas.llms import LangchainLLMWrapper # To wrap Ollama for RAGAS\n",
    "from datasets import Dataset\n",
    "import asyncio # Ragas evaluation is often async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfcf5381-03e5-4183-bf00-bf88ffe43f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and Processing PDFs...\n",
      "-> Loading: BES-COVID-Pract-Recomnd-06-June-Final-Copy.pdf\n",
      "   Loaded 38 pages.\n",
      "-> Loading: BES-Ramadan-Guideline-2020-min.pdf\n",
      "   Loaded 46 pages.\n",
      "-> Loading: Diabetes_Care_BADAS_guideline2019-3.pdf\n",
      "   Loaded 79 pages.\n",
      "-> Loading: Insulin-Guideline-min.pdf\n",
      "   Loaded 93 pages.\n",
      "\n",
      "Total documents loaded: 256\n",
      "\n",
      "Sample Document Metadata (first doc):\n",
      "{'producer': 'Nitro PDF PrimoPDF', 'creator': 'PrimoPDF http://www.primopdf.com', 'creationdate': '2020-06-07T20:17:39-06:00', 'moddate': '2020-06-07T20:17:39-06:00', 'title': 'Microsoft Word - BES COVID Pract Recomnd 06 June Final Copy', 'author': 'Mir', 'source': 'BES-COVID-Pract-Recomnd-06-June-Final-Copy.pdf', 'total_pages': 38, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "Sample Document Content (first 500 chars of first doc):\n",
      "Bangladesh Endocrine Society (BES) \n",
      "Practical Recommendations for Management of \n",
      "Diabetes and Other Endocrine Diseases in Patients with \n",
      "COVID-19 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Published Online June 2020 \n",
      " \n",
      " \n",
      "All rights reserved by: Bangladesh Endocrine Society (BES) \n",
      " \n",
      " \n",
      "Published by \n",
      "Bangladesh Endocrine Society (BES) \n",
      "Website: http://bes-org.net \n",
      "E-mail: \n",
      "endobd2012@gmail.com\n"
     ]
    }
   ],
   "source": [
    "pdf_files = [\n",
    "    r\"E:\\DiabetIQ\\LLM\\PDFs\\BES-COVID-Pract-Recomnd-06-June-Final-Copy.pdf\",\n",
    "    r\"E:\\DiabetIQ\\LLM\\PDFs\\BES-Ramadan-Guideline-2020-min.pdf\",\n",
    "    r\"E:\\DiabetIQ\\LLM\\PDFs\\Diabetes_Care_BADAS_guideline2019-3.pdf\",\n",
    "    r\"E:\\DiabetIQ\\LLM\\PDFs\\Insulin-Guideline-min.pdf\"\n",
    "]\n",
    "\n",
    "all_docs = []\n",
    "print(\"Loading and Processing PDFs...\")\n",
    "for pdf_path in pdf_files:\n",
    "    try:\n",
    "        file_name = os.path.basename(pdf_path)\n",
    "        print(f\"-> Loading: {file_name}\")\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        pages = loader.load_and_split() # load_and_split is often sufficient\n",
    "        for page_doc in pages:\n",
    "            page_doc.metadata['source'] = file_name\n",
    "        all_docs.extend(pages)\n",
    "        print(f\"   Loaded {len(pages)} pages.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {pdf_path}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal documents loaded: {len(all_docs)}\")\n",
    "if not all_docs:\n",
    "    print(\"\\nNo documents were loaded successfully. Exiting.\")\n",
    "    exit()\n",
    "else:\n",
    "    print(\"\\nSample Document Metadata (first doc):\")\n",
    "    print(all_docs[0].metadata)\n",
    "    print(\"\\nSample Document Content (first 500 chars of first doc):\")\n",
    "    print(all_docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "405debe9-e4cb-46f1-89fb-0d9e821960c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total chunks created: 702\n",
      "\n",
      "Sample Chunk Metadata (first chunk):\n",
      "{'producer': 'Nitro PDF PrimoPDF', 'creator': 'PrimoPDF http://www.primopdf.com', 'creationdate': '2020-06-07T20:17:39-06:00', 'moddate': '2020-06-07T20:17:39-06:00', 'title': 'Microsoft Word - BES COVID Pract Recomnd 06 June Final Copy', 'author': 'Mir', 'source': 'BES-COVID-Pract-Recomnd-06-June-Final-Copy.pdf', 'total_pages': 38, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "Sample Chunk Content (first 500 chars):\n",
      "Bangladesh Endocrine Society (BES) \n",
      "Practical Recommendations for Management of \n",
      "Diabetes and Other Endocrine Diseases in Patients with \n",
      "COVID-19 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Published Online June 2020 \n",
      " \n",
      " \n",
      "All rights reserved by: Bangladesh Endocrine Society (BES) \n",
      " \n",
      " \n",
      "Published by \n",
      "Bangladesh Endocrine Society (BES) \n",
      "Website: http://bes-org.net \n",
      "E-mail: \n",
      "endobd2012@gmail.com\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \", \", \" \", \"\"],\n",
    "    length_function=len,\n",
    ")\n",
    "chunks = text_splitter.split_documents(all_docs)\n",
    "print(f\"\\nTotal chunks created: {len(chunks)}\")\n",
    "if not chunks:\n",
    "    print(\"\\nNo chunks were created. Check splitting process. Exiting.\")\n",
    "    exit()\n",
    "else:\n",
    "    print(\"\\nSample Chunk Metadata (first chunk):\")\n",
    "    print(chunks[0].metadata)\n",
    "    print(\"\\nSample Chunk Content (first 500 chars):\")\n",
    "    print(chunks[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34eb9685-a69d-400e-932a-d0222d8cffde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing Embedding Model...\n",
      "\n",
      "Creating Vector Store (ChromaDB)...\n",
      "Vector Store Created.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nInitializing Embedding Model...\")\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"intfloat/e5-small-v2\")\n",
    "\n",
    "print(\"\\nCreating Vector Store (ChromaDB)...\")\n",
    "# Using in-memory Chroma for simplicity in this example\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model\n",
    ")\n",
    "print(\"Vector Store Created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "083be770-dce7-4511-845d-775b1bbebe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever configured (using k=5).\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5}) # Retrieve top 5 chunks\n",
    "print(f\"Retriever configured (using k={retriever.search_kwargs.get('k', 'default')}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f57adb7f-14c0-4670-a960-1ec85bc7d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are DiabetIQ, an AI assistant specializing in diabetes management for patients in Bangladesh, based *strictly* on the provided context documents.\n",
    "\n",
    "Context Documents:\n",
    "{context}\n",
    "\n",
    "Based *only* on the information in the numbered context documents above, answer the following question concisely and directly.\n",
    "Your advice should be actionable and consider general practices relevant to Bangladesh where possible (e.g., common foods mentioned in context, local guidelines if present in context).\n",
    "Do *not* add information that is not present in the context.\n",
    "If the context does not contain the answer, state that clearly.\n",
    "Always conclude your response by advising the user to consult a healthcare professional for personalized medical advice.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66f21041-54da-4118-a360-7dbb3acc380c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing LLM (Ollama - Mistral)...\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing LLM (Ollama - Mistral)...\")\n",
    "llm = OllamaLLM(model=\"mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "558ddd31-e16d-470a-a0ae-c1a13716fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs_with_metadata(docs: list[Document]) -> str:\n",
    "    \"\"\"Formats retrieved documents including source and page.\"\"\"\n",
    "    formatted_strings = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        # Ensure metadata keys exist, provide defaults if not\n",
    "        source = doc.metadata.get('source', 'N/A')\n",
    "        page = doc.metadata.get('page', 'N/A') # PyPDFLoader adds 'page'\n",
    "        metadata_str = f\"Source: {source}, Page: {page}\"\n",
    "        content_str = doc.page_content.replace('\\n', ' ').strip()\n",
    "        formatted_strings.append(f\"{i+1}. [{metadata_str}] {content_str}\")\n",
    "    return \"\\n\\n\".join(formatted_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54e17020-3566-4942-b89b-8105800c3c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_format(query: str) -> dict:\n",
    "    docs = retriever.invoke(query)\n",
    "    formatted_context = format_docs_with_metadata(docs)\n",
    "    # We also need the raw context content for RAGAS\n",
    "    raw_context_list = [doc.page_content for doc in docs]\n",
    "    return {\"formatted_context\": formatted_context, \"raw_contexts\": raw_context_list, \"question\": query}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c21b9f05-ce23-46ba-bf0a-099ae74bfa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_answer_chain = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7354ddbb-3387-47bb-af63-12379c77aa39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing for RAGAS Evaluation ---\n"
     ]
    }
   ],
   "source": [
    "# --- RAGAS Evaluation Section ---\n",
    "\n",
    "print(\"\\n--- Preparing for RAGAS Evaluation ---\")\n",
    "\n",
    "# 1. Define Evaluation Questions and Ground Truths\n",
    "\n",
    "eval_data = [\n",
    "    {\n",
    "        \"question\": \"How can I control my blood sugar level with diet according to the textbook?\",\n",
    "        \"ground_truth\": \"Dietary control involves emphasizing fruits, legumes, whole grains, dairy, learning carbohydrate counting, avoiding sugary drinks, ensuring sufficient protein (e.g., 1g/kg for older people), consuming 2-3 servings of fruits/vegetables daily, favoring mono/polyunsaturated fats (like from fatty fish, nuts, seeds), maintaining a regular schedule, and seeking medical help if unable to eat/hydrate. Personalized advice from a healthcare professional is essential.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What does the BADAS guideline say about insulin initiation?\",\n",
    "        \"ground_truth\": \"The BADAS Guideline 2019 recommends starting glucose-insulin infusion for all major surgeries. Outside surgery, if already on insulin, intermediate/long-acting insulin is continued (dose might need reduction), and short-acting insulin is adjusted based on blood glucose and food. Always consult a healthcare professional.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Tell me about managing diabetes during Ramadan based on the provided texts.\",\n",
    "        \"ground_truth\": \"Management during Ramadan includes a balanced diet (considering common Bangladeshi foods), adequate hydration during non-fasting hours, taking medication as prescribed (possibly adjusted), taking suhoor before dawn and iftar at sunset, regular blood glucose monitoring, moderate physical activity (avoiding intense workouts near meals), rest, stress management, and consulting a healthcare professional for personalized advice. [Reference specific advice from BES-Ramadan-Guideline-2020-min.pdf if possible]\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Can people with diabetes eat mangoes during Ramadan?\",\n",
    "        \"ground_truth\": \"The provided context does not explicitly state whether people with diabetes can eat mangoes during Ramadan. General advice emphasizes balanced meals and carbohydrate counting. Mangoes are high in sugar, so portion control and monitoring blood glucose would be crucial. Consult a healthcare professional for personalized advice regarding specific foods like mangoes.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "014a615f-755d-42cb-bde6-ed34a3c5ba52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data for RAGAS evaluation...\n",
      "  Processing question: How can I control my blood sugar level with diet a...\n",
      "  Processing question: What does the BADAS guideline say about insulin in...\n",
      "  Processing question: Tell me about managing diabetes during Ramadan bas...\n",
      "  Processing question: Can people with diabetes eat mangoes during Ramada...\n",
      "Data collection complete. Collected 4 results.\n"
     ]
    }
   ],
   "source": [
    "# 2. Collect Data for RAGAS (Question, Answer, Contexts, Ground Truth)\n",
    "print(\"Collecting data for RAGAS evaluation...\")\n",
    "evaluation_results = []\n",
    "for item in eval_data:\n",
    "    question = item[\"question\"]\n",
    "    ground_truth = item[\"ground_truth\"]\n",
    "    print(f\"  Processing question: {question[:50]}...\")\n",
    "\n",
    "    # a. Retrieve contexts\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    contexts_list = [doc.page_content for doc in retrieved_docs]\n",
    "    formatted_context_string = format_docs_with_metadata(retrieved_docs)\n",
    "\n",
    "    # b. Generate Answer using the LLM\n",
    "    try:\n",
    "        response = generate_answer_chain.invoke({\n",
    "            \"context\": formatted_context_string,\n",
    "            \"question\": question\n",
    "        })\n",
    "        answer = response.strip() # Get the generated answer\n",
    "    except Exception as e:\n",
    "        print(f\"    Error generating answer for '{question[:50]}...': {e}\")\n",
    "        answer = \"[Error generating answer]\"\n",
    "        contexts_list = [] # Avoid evaluating if generation failed badly\n",
    "\n",
    "    # c. Store results\n",
    "    evaluation_results.append({\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"contexts\": contexts_list, # List of strings (document content)\n",
    "        \"ground_truth\": ground_truth\n",
    "    })\n",
    "\n",
    "print(f\"Data collection complete. Collected {len(evaluation_results)} results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c18175ad-0c1b-4f48-9d35-e317f6d0835d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation dataset created:\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'contexts', 'ground_truth'],\n",
      "    num_rows: 4\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# 3. Convert to Hugging Face Dataset\n",
    "if evaluation_results:\n",
    "    dataset_dict = {\n",
    "        \"question\": [item[\"question\"] for item in evaluation_results],\n",
    "        \"answer\": [item[\"answer\"] for item in evaluation_results],\n",
    "        \"contexts\": [item[\"contexts\"] for item in evaluation_results],\n",
    "        \"ground_truth\": [item[\"ground_truth\"] for item in evaluation_results],\n",
    "    }\n",
    "    eval_dataset = Dataset.from_dict(dataset_dict) # <-- This line creates it\n",
    "    print(\"\\nEvaluation dataset created:\")\n",
    "    print(eval_dataset)\n",
    "else:\n",
    "    print(\"\\nNo evaluation results collected, skipping RAGAS evaluation.\")\n",
    "    # exit() # You might have an exit() here, which would stop the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe03632d-c588-4e6c-83d9-84387e56f699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Configuring RAGAS ---\n",
      "  Judge LLM created: LangChain OllamaLLM (model='llama3')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Configuring RAGAS ---\")\n",
    "\n",
    "judge_llm_model = OllamaLLM(model=\"llama3\") # Or change to a faster model if needed\n",
    "print(f\"  Judge LLM created: LangChain OllamaLLM (model='{judge_llm_model.model}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e41eef3-810b-4458-bd29-7eb54076b7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Embeddings created: LangChain HuggingFaceEmbeddings (model='intfloat/e5-small-v2')\n"
     ]
    }
   ],
   "source": [
    "# 2. Configure the Embeddings for RAGAS (using the same as your pipeline)\n",
    "\n",
    "base_embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/e5-small-v2\")\n",
    "print(f\"  Embeddings created: LangChain HuggingFaceEmbeddings (model='{base_embeddings.model_name}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec054b1b-1297-45cb-b3c6-b768d1e98b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RAGAS Metrics defined:\n",
      "    - faithfulness\n",
      "    - answer_relevancy\n",
      "    - context_precision\n",
      "    - context_recall\n",
      "    - answer_correctness\n",
      "--- RAGAS Configuration Complete ---\n"
     ]
    }
   ],
   "source": [
    "# 3. Define the metrics for evaluation\n",
    "metrics = [\n",
    "    faithfulness,        # How factually consistent is the answer with the context? (LLM judged)\n",
    "    answer_relevancy,    # How relevant is the answer to the question? (LLM + Embedding judged)\n",
    "    context_precision,   # Signal-to-noise ratio in retrieved contexts. (LLM judged)\n",
    "    context_recall,      # How well does the context capture the necessary info from ground_truth? (LLM judged)\n",
    "    answer_correctness   # How accurate is the answer compared to the ground_truth? (LLM judged)\n",
    "]\n",
    "print(\"  RAGAS Metrics defined:\")\n",
    "for m in metrics:\n",
    "    print(f\"    - {m.name}\")\n",
    "\n",
    "print(\"--- RAGAS Configuration Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1950ff-74d5-4281-a04f-f93e37fe99a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asyncio event loop found.\n",
      "\n",
      "--- Starting RAGAS Evaluation ---\n",
      "Using Judge LLM: llama3\n",
      "Using Embeddings: intfloat/e5-small-v2\n",
      "Evaluating 4 samples with 5 metrics each.\n",
      "This may take a while, especially with local LLMs...\n",
      "Ensure Ollama is running and accessible.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4def3414e0b4572aecdab255b1c7902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[0]: TimeoutError()\n",
      "Exception raised in Job[2]: TimeoutError()\n",
      "Exception raised in Job[3]: TimeoutError()\n",
      "Exception raised in Job[4]: TimeoutError()\n",
      "Exception raised in Job[5]: TimeoutError()\n",
      "Exception raised in Job[7]: TimeoutError()\n",
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[9]: TimeoutError()\n",
      "Exception raised in Job[10]: TimeoutError()\n",
      "Exception raised in Job[12]: TimeoutError()\n",
      "Exception raised in Job[13]: TimeoutError()\n",
      "Exception raised in Job[14]: TimeoutError()\n",
      "Exception raised in Job[15]: TimeoutError()\n",
      "Exception raised in Job[1]: TimeoutError()\n",
      "Exception raised in Job[6]: TimeoutError()\n",
      "Exception raised in Job[11]: TimeoutError()\n"
     ]
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "try:\n",
    "    loop = asyncio.get_running_loop()\n",
    "    print(\"Asyncio event loop found.\")\n",
    "except RuntimeError:\n",
    "    print(\"No running asyncio event loop, creating one.\")\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "\n",
    "if eval_dataset:\n",
    "    print(\"\\n--- Starting RAGAS Evaluation ---\")\n",
    "    print(f\"Using Judge LLM: {judge_llm_model.model}\")\n",
    "    print(f\"Using Embeddings: {base_embeddings.model_name}\")\n",
    "    print(f\"Evaluating {len(eval_dataset)} samples with {len(metrics)} metrics each.\")\n",
    "    print(\"This may take a while, especially with local LLMs...\")\n",
    "    print(\"Ensure Ollama is running and accessible.\")\n",
    "\n",
    "    try:\n",
    "        # Key Change: Pass the LangChain LLM and Embeddings objects directly\n",
    "        # RAGAS v0.1.0+ prefers this over the older LangchainLLMWrapper approach.\n",
    "        result = evaluate(\n",
    "            dataset=eval_dataset,       # The dataset prepared earlier\n",
    "            metrics=metrics,            # The list of base metrics\n",
    "            llm=judge_llm_model,        # The LangChain LLM object for judging\n",
    "            embeddings=base_embeddings, # The LangChain Embeddings object\n",
    "            # raise_exceptions=False    # Set to False to log errors and continue, True (default) to stop on first error.\n",
    "                                        # Let's keep it True for now to see errors clearly.\n",
    "        )\n",
    "\n",
    "        print(\"--- RAGAS Evaluation Complete ---\")\n",
    "\n",
    "        # Display results\n",
    "        print(\"\\nEvaluation Results:\")\n",
    "        results_df = result.to_pandas()\n",
    "\n",
    "        # Improve Display\n",
    "        pd.set_option('display.max_colwidth', None) # Show full text in columns\n",
    "        pd.set_option('display.max_columns', None)  # Show all columns\n",
    "        pd.set_option('display.float_format', '{:.4f}'.format) # Format scores\n",
    "\n",
    "        print(results_df)\n",
    "\n",
    "        print(\"\\n--- Interpreting Scores (Scale 0.0 to 1.0, higher is better) ---\")\n",
    "        print(\"- faithfulness: Does the answer stick to the provided context? High = Less hallucination.\")\n",
    "        print(\"- answer_relevancy: Is the answer relevant to the question? High = On-topic answer.\")\n",
    "        print(\"- context_precision: Are the retrieved contexts relevant? High = Less noise in context.\")\n",
    "        print(\"- context_recall: Did the retriever find all necessary contexts (based on ground_truth)? High = Good retrieval coverage.\")\n",
    "        print(\"- answer_correctness: Is the answer factually correct compared to the ground truth? High = Accurate answer.\")\n",
    "        print(\"\\nNaN scores indicate the metric calculation failed, often due to timeouts or errors from the Judge LLM.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- RAGAS Evaluation Failed ---\")\n",
    "        print(f\"An error occurred during evaluation: {e}\")\n",
    "        print(\"Potential Causes & Fixes:\")\n",
    "        print(\"  1. Ollama Server Down: Ensure 'ollama serve' is running and the judge model ({judge_llm_model.model}) is available.\")\n",
    "        print(\"  2. Network Issues: Check if the script can reach the Ollama server address (usually http://localhost:11434).\")\n",
    "        print(\"  3. Judge LLM Too Slow (Timeout):\")\n",
    "        print(\"     - Use a smaller/faster judge LLM model in Ollama (e.g., 'phi3:mini', 'mistral').\")\n",
    "        print(\"     - Increase hardware resources (RAM, CPU/GPU) for Ollama.\")\n",
    "        print(\"     - If using LangChain's Ollama wrapper, try increasing 'request_timeout' when creating `judge_llm_model` (see config cell).\")\n",
    "        print(\"  4. Insufficient Ground Truth: Some metrics rely heavily on good ground truth.\")\n",
    "        print(\"  5. RAGAS/Dependency Issues: Ensure RAGAS and its dependencies (langchain, datasets, etc.) are up-to-date.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping RAGAS evaluation as eval_dataset is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b943a87-b908-492e-8388-71a95e4b5a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
