{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0d53cd6-1188-47e9-ba9c-61a8ce58c639",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858d78e5-6bed-4311-a212-e134af8a7eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Ensure the environment variables are set\n",
    "langchain_api_key = os.getenv('LANGCHAIN_API_KEY')\n",
    "huggingface_api_key = os.getenv('HUGGINGFACE_API_KEY')\n",
    "\n",
    "if not langchain_api_key:\n",
    "    raise ValueError(\"LANGCHAIN_API_KEY is not set in the environment variables.\")\n",
    "if not huggingface_api_key:\n",
    "    raise ValueError(\"HUGGINGFACE_API_KEY is not set in the environment variables.\")\n",
    "\n",
    "# Set environment variables for the application\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_API_KEY'] = langchain_api_key\n",
    "os.environ['HUGGINGFACE_API_KEY'] = huggingface_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25522a91-1e7f-415b-af52-dfa711519d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7de2d89-8afe-41fb-bc55-3ab2a8820ea1",
   "metadata": {},
   "source": [
    "# Load Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9285078-099a-4221-8529-7962100e7229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DIABETES CARE \\nBADAS Guideline 2019 \\n          \\n  \\n   \\n  \\n   P|) \\nDAS GUELINE ON Man \\nDELIT IGEMEN \\n  \\nA Joint Initiative of \\nDiabetic Association of Bangladesh \\nNCDC Program, Directorate General of Health Services'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Documents (use PyPDFLoader for PDF)\n",
    "file_path = r\"C:\\Users\\User\\Desktop\\NSU\\CSE299 Materials\\LLM\\Dataset\\Diabetes_Care_BADAS_guideline2019-3.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "\n",
    "docs[0].page_content[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956c6370-6f96-4b34-b4c8-023540c4089e",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85911a9d-14bb-4c49-9e29-7f9b22ed67df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 ---\n",
      "DIABETES CARE \n",
      "BADAS Guideline 2019 \n",
      "          \n",
      "  \n",
      "   \n",
      "  \n",
      "   P|) \n",
      "DAS GUELINE ON Man \n",
      "DELIT IGEMEN \n",
      "  \n",
      "A Joint Initiative of \n",
      "Diabetic Association of Bangladesh \n",
      "NCDC Program, Directorate General of Health Services\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--- Chunk 2 ---\n",
      "DIABETES CARE \n",
      "BADAS Guideline 2019 \n",
      "  \n",
      "A Joint Initiative of \n",
      "Diabetic Association of Bangladesh \n",
      "NCDC Program, Directorate General of Health Services \n",
      "  \n",
      "Diabetes Care: BADAS Guideline 2019 HEI! 1\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "--- Chunk 3 ---\n",
      "DIABETES CARE: BADAS GUIDELINE 2019 \n",
      "Convener: Prof A K Azad Khan \n",
      "Chairman: Prof Hajera Mahtab \n",
      "Members of the steering committee \n",
      "Prof Dr AHM Enayet Hossain \n",
      "Prof Akhtar Hussain \n",
      "Prof Zafar Anmed Latif \n",
      "Prof Tofail Ahmed \n",
      "Prof Laique Ahmed Khan \n",
      "Prof Nazrul Islam Siddiqui \n",
      "Prof Md Hafizur Rahman \n",
      "Prof Abdus Saleque Mollah \n",
      "Prof Md Farid Uddin \n",
      "Prof M A Jalil Ansary \n",
      "Prof Dr MA Samad \n",
      "Prof SM Ashrafuzzaman \n",
      "Prof MA Hasnat \n",
      "Dr Kazi Ali Hassan \n",
      "Dr Abdul Mannan Sarker \n",
      "Members of the Task Force \n",
      "Prof Md Faruque Pathan \n",
      "Dr Tareen Ahmed \n",
      "Dr Md Feroz Amin \n",
      "Dr Faria Afsana \n",
      "Dr Bishwajit Bhowmik \n",
      "Dr Nazmul Kabir Qureshi \n",
      "Dr Indrajit Prasad \n",
      "Dr Tanjina Hossain \n",
      "Dr Shahjada Selim \n",
      "Dr M Saifuddin \n",
      "Dr Tasnima Siddiquee \n",
      "Dr Abdul Alim \n",
      "Published \n",
      "November 2019 \n",
      "Correspondence \n",
      "Diabetic Association of Bangladesh \n",
      "122 Kazi Nazrul Islam Avenue, Dhaka 1000, Bangladesh \n",
      "Design and layout \n",
      "Liason Office,122 Kazi Nazrul Islam avenue, Shabag, Dhaka \n",
      "Printing \n",
      "BADAS-RVTC Printing Press\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "for i, chunk in enumerate(splits[:3]):  # Show the first 3 chunks\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(chunk.page_content[:1000])  # Print the first 1000 characters of the chunk\n",
    "    print(\"\\n\" + \"-\"*70 + \"\\n\")  # Separator between chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb03e0d-74de-4c2b-b98d-20b2df695835",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0150fece-837b-4024-925f-cc2542f818fd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a115c38f11364f8685e5e823410f442d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\NSU\\CSE299 Materials\\LLM\\my_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4b7c60a6b94e399c610ed1378ad6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca94a4c7f164dacbc742311e350c64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebbfe90420f4a9b805d03f3792e562e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c444f47e184cdf9b481e6580a74d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f66123de3144389b28464490ceba2ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a174e219404229bd627adea122c163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbed04e5f9c4d7b9e2d5e175c45c0f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ed90aa4fb444319b2a14c149830cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1d5a7932ab413caf4a9cc1c2067f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef30943238c94555bdcd156851639211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling%2Fconfig.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Use HuggingFace Embeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embedding_model)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36f5a63-a7ab-40df-8333-1b33923d33b1",
   "metadata": {},
   "source": [
    "# Retrieval and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4476e9f3-380d-49f3-a654-7fecf6da625e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_16516\\4263663696.py:8: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3.2\")\n"
     ]
    }
   ],
   "source": [
    "#### RETRIEVAL and GENERATION ####\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# LLM\n",
    "llm = Ollama(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8e987c6-3480-40b9-b5eb-8b15d412a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bb47ec8-3f6c-423c-9f5b-1885bf9ebe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b701e174-78b8-424d-91b7-21f29329c7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pathophysiology refers to the study of the physiological changes that occur within an organism or system as a result of disease. In the context of diabetes, pathophysiology examines the underlying mechanisms and processes that lead to hyperglycemia. It involves understanding how various factors such as insulin production, resistance, and secretion contribute to glucose intolerance in diabetic individuals.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question\n",
    "rag_chain.invoke(\"What is Pathophysiology?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147a460a-38e9-4d7c-ace0-c2a66238673a",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb1de7b-7919-448f-9c1e-0df5f3237ff6",
   "metadata": {},
   "source": [
    "## Count tokens with tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e53bdb2a-b194-4e5f-9980-c4b14829aad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "question = \"What is Pathophysiology?\"\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string(question, \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f723061f-d5d3-4b6a-bcd4-ea8560c1e1c7",
   "metadata": {},
   "source": [
    "## Text Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93d61f5a-71ec-4d50-8313-f15b1356fcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_16516\\3738655753.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Embed a single query\n",
    "query_result = embedding_model.embed_query(question)  \n",
    "\n",
    "# Embed multiple documents (convert to text first)\n",
    "document_result = embedding_model.embed_documents([doc.page_content for doc in docs])\n",
    "\n",
    "# Check the length of query embedding\n",
    "print(len(query_result))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07825825-e6f7-4a6c-a402-43a62a8f41f8",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "700567d0-1db5-44dc-bbb1-bbcc0da51197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Similar Documents:\n",
      "1. Document 15 - Similarity: 0.4113\n",
      "2. Document 11 - Similarity: 0.2673\n",
      "3. Document 34 - Similarity: 0.2346\n",
      "4. Document 13 - Similarity: 0.2219\n",
      "5. Document 8 - Similarity: 0.2194\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec2, vec1)  \n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2, axis=1)  # Compute norms for each document\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "# Convert document embeddings to NumPy array\n",
    "document_embeddings = np.array(document_result)  \n",
    "\n",
    "# Compute cosine similarity for each document\n",
    "similarities = cosine_similarity(query_result, document_embeddings)\n",
    "\n",
    "# Get the top 5 most similar documents\n",
    "top_indices = np.argsort(similarities)[::-1][:5]  # Sort in descending order and take top 5\n",
    "\n",
    "# Print results\n",
    "print(\"Top 5 Similar Documents:\")\n",
    "for i, idx in enumerate(top_indices):\n",
    "    print(f\"{i+1}. Document {idx} - Similarity: {similarities[idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b41ceaf-4dc6-4d49-961a-9faf611e8d81",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cddbec2f-1fff-41ad-a0d5-ac8503a5de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings  \n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create a Chroma vector store\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embedding_model)\n",
    "\n",
    "# Convert to a retriever\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e49959-952a-40e1-a895-75298f51f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"What is Pathophysiology?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "203c1cba-84c8-4f24-b43a-b8aaebd5edc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc09f6ae-d9cc-4a1e-ba74-35e2c3bf0fed",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66a81cf4-8ccf-4351-a40d-f2502463944a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\\n'), additional_kwargs={})])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06665fab-5190-4628-bfe0-695e16f60d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "llm = Ollama(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "34780c1a-a075-4053-8156-b41a767c83c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "67e5de03-c76e-45d3-9fea-ccfd3341c362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The text refers to \"Pathophysiology\" as the main topic for section 1.2 on two separate occasions, describing it as:\\n\\n- The \"hall mark\" of Type 1 diabetes.\\n- A description of the main pathophysiologic defects in type 2 diabetes.\\n\\nIn both cases, Pathophysiology is described as the study of the normal functions and abnormal function of living organisms and their parts, particularly in relation to disease.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run\n",
    "chain.invoke({\"context\":docs,\"question\":\"What is Pathophysiology?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f7240d2-caf6-49c4-ab08-a356eac92395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt_hub_rag = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c5eddaa7-1ada-47c7-8863-c926b53e51a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_hub_rag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1840a956-49d1-4216-8d79-14c5c2a015f1",
   "metadata": {},
   "source": [
    "# RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4e9ad2d4-263b-4f1a-838e-e782dd648c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the document, Pathophysiology refers to:\\n\\n\"Pathophysiology: Type 1 diabetes: Marked impairment of insulin production due to cellular-mediated autoimmune destruction of beta cells is the hall mark. Some of type 1 diabetes cases are of idiopathic in nature. Type 2 diabetes: Insulin resistance and 6-cell failure represent the main pathophysiologic defects in type 2 diabetes.\"\\n\\nAdditionally, it mentions that these eight pathways comprise \"the ominous octet\" for the development of glucose intolerance in type 2 diabetic individuals.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"What is Pathophysiology?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
